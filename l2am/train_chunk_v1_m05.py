# train_chunk_v3.py
import os

os.environ["TOKENIZERS_PARALLELISM"] = "false"
from transformers import (
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding
)
from sklearn.metrics import classification_report, accuracy_score
import warnings
warnings.filterwarnings("ignore", message=".*beta.*renamed.*")
warnings.filterwarnings("ignore", message=".*gamma.*renamed.*")


# ======================
# 1. é…ç½®è·¯å¾„
# ======================
DATA_DIR = "data/l2am_r2r_v3/train/6"
CACHE_DIR = "data/cache/train_frames_chunk4_v1_6_m05"
VAL_DATA_DIR = "data/l2am_r2r_v3/val_seen/6"
VAL_CACHE_DIR = "data/cache/val_seen_frames_chunk4_v1_6_m05"
VAL_U_DATA_DIR = "data/l2am_r2r_v3/val_unseen/6"
VAL_U_CACHE_DIR = "data/cache/val_unseen_frames_chunk4_v1_6_m05"

NUM_GRID_R = 6
NUM_GRID_C = 6
HF_CACHE_DIR = "data/hf_model_cache"  # HF æ¨¡å‹ç¼“å­˜è·¯å¾„
RESUME_FROM_CHECKPOINT = None  # "outputs/l2a_longformer_action_classifier/checkpoint-500"  # è®¾ç½®ä¸ºæŸä¸ªæ£€æŸ¥ç‚¹è·¯å¾„ä»¥ä»è¯¥æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒï¼Œå¦åˆ™ä¸º None
# model configs
MODEL_NAME = "google/bigbird-roberta-base"  # å¯æ›¿æ¢ä¸º roberta-baseã€ bert-base-uncasedã€allenai/longformer-base-4096ã€google/bigbird-roberta-baseç­‰
MAX_LENGTH = 1024  # æ ¹æ®æ¨¡å‹è°ƒæ•´æœ€å¤§é•¿åº¦
NUM_CHUNK = 4  # ä¸ dataset_utils ä¸€è‡´

# æ•°æ®å¢å¼ºæ¯”ä¾‹ï¼šä»éªŒè¯é›†ä¸­æŠ½å–ä¸€éƒ¨åˆ†æ•°æ®åŠ å…¥è®­ç»ƒé›†
augment_ratio = 0.5  # å¯è°ƒæ•´æ¯”ä¾‹

# training configs
OUTPUT_DIR = "outputs/l2a_bigbird_action_classifier_chunk4_v1_6_m05"
NUM_EPOCHS = 30
PER_DEVICE_TRAIN_BATCH_SIZE = 12
PER_DEVICE_EVAL_BATCH_SIZE = 128
GRADIENT_ACCUMULATION_STEPS = 1
LEARNING_RATE = 6e-5
WARMUP_RATIO = 0.02  # å­¦ä¹ ç‡é¢„çƒ­æ¯”ä¾‹
WANDB_RUN_NAME = "bigbird-action-chunk4-pred-depth-sem-v1-6-m05"  # å¯é€‰ï¼šè®¾ç½® wandb å®éªŒåç§°
LOGGING_STEPS = 100
EVAL_STEPS = 500
SAVE_STEPS = 500

# ======================
# 2. åŠ è½½æˆ–é¢„å¤„ç†æ•°æ®é›†
# ======================
from dataset_utils import get_or_create_dataset_chunk_v1


# ======================
# 3. Tokenize å‡½æ•°
# ======================
from dataset_utils import tokenize_function


# ======================
# 4. ä¸»è®­ç»ƒæµç¨‹
# ======================
def main():
    # åŠ è½½åˆ†è¯å™¨
    from transformers import BigBirdTokenizer

    tokenizer = BigBirdTokenizer.from_pretrained(
        MODEL_NAME,
        cache_dir=HF_CACHE_DIR,
        clean_up_tokenization_spaces=True,
    )
    
    # Step 1: è·å–å¸§çº§æ•°æ®é›†
    ds = get_or_create_dataset_chunk_v1(DATA_DIR, CACHE_DIR, num_grid_r=NUM_GRID_R, num_grid_c=NUM_GRID_C, num_chunk=NUM_CHUNK)
    vds = get_or_create_dataset_chunk_v1(VAL_DATA_DIR, VAL_CACHE_DIR, num_grid_r=NUM_GRID_R, num_grid_c=NUM_GRID_C, num_chunk=NUM_CHUNK)
    vuds = get_or_create_dataset_chunk_v1(VAL_U_DATA_DIR, VAL_U_CACHE_DIR, num_grid_r=NUM_GRID_R, num_grid_c=NUM_GRID_C, num_chunk=NUM_CHUNK)

    # Step 2: åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    # ds = ds.train_test_split(test_size=0.1, seed=42)
    train_ds = ds
    eval_ds = vds

    # å°† vds å’Œ vuds çš„ä¸€å®šæ¯”ä¾‹æ•°æ®åŠ å…¥è®­ç»ƒé›†ä»¥å¢å¼ºè®­ç»ƒ
    from datasets import concatenate_datasets
    vds_sampled = vds.shuffle(seed=42).select(range(int(len(vds) * augment_ratio)))
    vuds_sampled = vuds.shuffle(seed=42).select(range(int(len(vuds) * augment_ratio)))
    train_ds = concatenate_datasets([train_ds, vds_sampled, vuds_sampled])

    # Step 3: Tokenize
    # å¦‚æœæ²¡æœ‰äº‹å…ˆä¿å­˜çš„æ•°æ®é›†ï¼Œåˆ™åˆ›å»ºæ•°æ®é›†
    if os.path.exists(os.path.join(OUTPUT_DIR, "tokenized_train")) and os.path.exists(os.path.join(OUTPUT_DIR, "tokenized_eval")):
        print("Loading tokenized datasets from disk directory:", OUTPUT_DIR)
        from datasets import load_from_disk
        tokenized_train = load_from_disk(os.path.join(OUTPUT_DIR, "tokenized_train"))
        tokenized_eval = load_from_disk(os.path.join(OUTPUT_DIR, "tokenized_eval"))
    else:
        print("Creating and tokenizing datasets...")    
        tokenized_train = train_ds.map(
            lambda x: tokenize_function(x, tokenizer, max_length=MAX_LENGTH),
            batched=True,
            remove_columns=["prompt"],
            num_proc=48  # ğŸ‘ˆ å…³é”®ï¼ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ tokenize
        )
        tokenized_eval = eval_ds.map(
            lambda x: tokenize_function(x, tokenizer, max_length=MAX_LENGTH),
            batched=True,
            remove_columns=["prompt"],
            num_proc=48  # ğŸ‘ˆ å…³é”®ï¼ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ tokenize
        )

        # åœ¨ train.py çš„ tokenization éƒ¨åˆ†ï¼š
        tokenized_train = tokenized_train.rename_column("action_chunk", "labels")
        tokenized_eval = tokenized_eval.rename_column("action_chunk", "labels")

        # ä¿å­˜æ•°æ®é›†ä»¥åè®­ç»ƒæ—¶å¯ç›´æ¥åŠ è½½
        tokenized_train.save_to_disk(os.path.join(OUTPUT_DIR, "tokenized_train"))
        tokenized_eval.save_to_disk(os.path.join(OUTPUT_DIR, "tokenized_eval"))

    # Step 4: ç¡®å®šç±»åˆ«æ•°
    num_labels = len(set(train_ds["action"]))
    print(f"Number of action classes: {num_labels}")

    # Step 5: åŠ è½½æ¨¡å‹
    # è®¡ç®—actionæƒé‡
    from sklearn.utils.class_weight import compute_class_weight
    import numpy as np
    import torch
    labels = np.array(train_ds["action"])
    prompts = np.array(train_ds["prompt"])
    # æ‰“å°ä¸€ä¸ªpromptç¤ºä¾‹ï¼š
    print("Example prompt:", prompts[0])
    print("Example labels chunk:", train_ds[0]["action_chunk"])
    class_weights = compute_class_weight(
        class_weight="balanced",
        classes=np.unique(labels),
        y=labels
    )
    class_weights = torch.tensor(class_weights, dtype=torch.float) # å¤šå¡è®­ç»ƒæ—¶æ”¾åœ¨ Trainer é‡Œå¤„ç†
    print("Class weights:", class_weights)

    from model_zoo import MultiStepWeightedClassifier
    model = MultiStepWeightedClassifier(
        MODEL_NAME,
        num_labels=num_labels,
        class_weights=class_weights,
        num_steps=NUM_CHUNK,
        cache_dir=HF_CACHE_DIR,
    )
    
    # æ£€æŸ¥å¯è®­ç»ƒå‚æ•°æ•°é‡
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"Total params: {total_params / 1e6:.1f}M")
    print(f"Trainable params: {trainable_params / 1e6:.1f}M ({trainable_params == total_params})")

    # Step 6: å®šä¹‰è¯„ä¼°æŒ‡æ ‡
    def compute_metrics(eval_pred):
        logits, labels = eval_pred  # logits: (N, NUM_CHUNK, num_labels), labels: (N, NUM_CHUNK)
        preds = np.argmax(logits, axis=-1)  # (N, NUM_CHUNK)

        metrics = {}
        total_acc = 0.0

        # å‡è®¾ num_labels = 4ï¼ˆæ ¹æ®ä½ çš„æ•°æ®ï¼‰
        num_labels = logits.shape[-1]

        for step in range(NUM_CHUNK):
            # å–å‡ºå½“å‰ step çš„æ ‡ç­¾å’Œé¢„æµ‹
            step_labels = labels[:, step]
            step_preds = preds[:, step]

            # è¿‡æ»¤æ‰ ignore_index (-100)
            valid_mask = step_labels != -100
            if not np.any(valid_mask):
                # å¦‚æœè¯¥ step æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼ˆæ¯”å¦‚å…¨æ˜¯ paddingï¼‰ï¼Œè·³è¿‡
                for cls_id in range(num_labels):
                    metrics[f"step{step}_recall_class_{cls_id}"] = 0.0
                    metrics[f"step{step}_f1_class_{cls_id}"] = 0.0
                metrics[f"step{step}_acc"] = 0.0
                continue

            step_labels = step_labels[valid_mask]
            step_preds = step_preds[valid_mask]

            # Accuracy
            acc = accuracy_score(step_labels, step_preds)
            metrics[f"step{step}_acc"] = acc
            total_acc += acc

            # Classification report per class
            report = classification_report(
                step_labels, step_preds,
                labels=list(range(num_labels)),  # æ˜¾å¼æŒ‡å®šæ‰€æœ‰ç±»åˆ«ï¼ˆå³ä½¿æœªå‡ºç°ï¼‰
                output_dict=True,
                zero_division=0
            )

            for cls_id in range(num_labels):
                cls_str = str(cls_id)
                metrics[f"step{step}_recall_class_{cls_id}"] = report[cls_str]["recall"]
                metrics[f"step{step}_f1_class_{cls_id}"] = report[cls_str]["f1-score"]

        metrics["mean_step_acc"] = total_acc / NUM_CHUNK

        # å¯é€‰ï¼šä¿ç•™ç¬¬ä¸€æ­¥çš„æ€»ä½“æŒ‡æ ‡ç”¨äºå…¼å®¹æˆ–å¯¹æ¯”
        if "step0_acc" in metrics:
            metrics["first_step_acc"] = metrics["step0_acc"]
            for cls_id in range(num_labels):
                metrics[f"first_step_recall_class_{cls_id}"] = metrics[f"step0_recall_class_{cls_id}"]
                metrics[f"first_step_f1_class_{cls_id}"] = metrics[f"step0_f1_class_{cls_id}"]

        return metrics


    # Step 7: è®­ç»ƒå‚æ•°
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=NUM_EPOCHS,
        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,
        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,
        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,
        learning_rate=LEARNING_RATE,          # â†â†â† å…³é”®ä¿®æ”¹ï¼šè®¾ç½®å­¦ä¹ ç‡
        warmup_ratio=WARMUP_RATIO,                # â†â†â† å…³é”®ä¿®æ”¹ï¼šè®¾ç½®å­¦ä¹ ç‡é¢„çƒ­æ¯”ä¾‹
        weight_decay=0.01,
        logging_steps=LOGGING_STEPS,
        eval_strategy="steps",
        eval_steps=EVAL_STEPS,
        save_strategy="steps",
        save_steps=SAVE_STEPS,
        load_best_model_at_end=True,
        # metric_for_best_model="eval_step0_f1_class_0",  # â†â†â† å…³é”®ä¿®æ”¹ï¼šä»¥ç½•è§ç±»F1ä¸ºæœ€ä½³æ¨¡å‹é€‰æ‹©æ ‡å‡†
        metric_for_best_model="eval_step0_acc",  
        greater_is_better=True,
        save_total_limit=4,
        report_to="wandb",                 # â†â†â† å…³é”®ï¼šå¯ç”¨ wandb
        run_name=WANDB_RUN_NAME,    # â† å¯é€‰ï¼šç»™å®éªŒå‘½å
        # report_to="none",
        seed=42,
        dataloader_num_workers=16,
        ddp_find_unused_parameters=True,  # â†â†â† æ·»åŠ è¿™ä¸€è¡Œæ¥æ‰“å¼€ddpçš„unused parameteræ£€æŸ¥
        save_safetensors=False,  # â†â†â† å…³é”®ï¼ç¦ç”¨ safetensorsä»¥é¿å…å…¼å®¹æ€§é—®é¢˜
    )

    # Step 8: æ•°æ®æ•´ç†å™¨
    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    # Step 9: åˆ›å»º Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_eval,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
    )

    # Step 10: å¼€å§‹è®­ç»ƒ
    print("ğŸš€ Starting training...")
    # ç»§ç»­ä¹‹å‰çš„è®­ç»ƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    # trainer.train(resume_from_checkpoint=True)
    if RESUME_FROM_CHECKPOINT is not None:
        print(f"Resuming training from checkpoint: {RESUME_FROM_CHECKPOINT}")
        trainer.train(resume_from_checkpoint=RESUME_FROM_CHECKPOINT)
    else:
        trainer.train()


    # Step 11: ä¿å­˜æœ€ç»ˆæ¨¡å‹
    trainer.save_model(os.path.join(OUTPUT_DIR, "final"))
    tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "final"))

    print(f"âœ… Training completed! Model saved to {os.path.join(OUTPUT_DIR, 'final')}")


if __name__ == "__main__":
    main()