#!/bin/bash

# ç”¨æ³•: ./launch_train_chunk_v3.sh <id> [suffix]
# ä¾‹å¦‚: ./launch_train_chunk_v3.sh 01 chunk8_v3

if [ $# -lt 1 ]; then
    echo "Usage: $0 <task_id> [suffix]"
    exit 1
fi

TASK_ID="$1"
SUFFIX="${2:-default}"

LOG_FILE="task${TASK_ID}_${SUFFIX}.log"
ERR_FILE="task${TASK_ID}_${SUFFIX}.err"
PID_FILE="task${TASK_ID}_${SUFFIX}.pid"

echo "ğŸš€ Starting task ${TASK_ID} with suffix '${SUFFIX}'"
echo "ğŸ“„ Log file: ${LOG_FILE}"
echo "âš ï¸  Error file: ${ERR_FILE}"
echo "ğŸ†” PID file: ${PID_FILE}"

# å¯åŠ¨è®­ç»ƒï¼ˆä½¿ç”¨ nohup ç¡®ä¿ç»ˆç«¯é€€å‡ºåä»è¿è¡Œï¼‰
nohup bash -c '
    torchrun \
        --nproc_per_node=6 \
        --master_port=29500 \
        l2am/train_chunk_v3.py \
        > "'"$LOG_FILE"'" 2> "'"$ERR_FILE"'"
    
    # è®­ç»ƒç»“æŸåè‡ªåŠ¨æ¸…ç† PID æ–‡ä»¶
    rm -f "'"$PID_FILE"'"
' &

# è·å– nohup å¯åŠ¨çš„ shell è¿›ç¨‹ PID
WRAPPER_PID=$!

# ç­‰å¾…å‡ ç§’è®© torchrun å’Œ python å­è¿›ç¨‹å¯åŠ¨
sleep 3

# å°è¯•æ‰¾åˆ°å®é™…å ç”¨ GPU çš„ python å­è¿›ç¨‹ PID
PYTHON_PID=""
# æ–¹æ³•ï¼šæŸ¥æ‰¾ WRAPPER_PID çš„å­è¿›ç¨‹ä¸­åŒ…å« "train_chunk_v3.py" çš„ python è¿›ç¨‹
while read -r pid ppid cmd; do
    if [[ "$ppid" == "$WRAPPER_PID" ]] && [[ "$cmd" == *"python"* ]] && [[ "$cmd" == *"train_chunk_v3.py"* ]]; then
        PYTHON_PID="$pid"
        break
    fi
done < <(ps -eo pid,ppid,args)

# å¦‚æœæ²¡æ‰¾åˆ°ï¼Œé€€è€Œæ±‚å…¶æ¬¡ç”¨ torchrun çš„ç›´æ¥å­è¿›ç¨‹ï¼ˆé€šå¸¸æ˜¯ pythonï¼‰
if [ -z "$PYTHON_PID" ]; then
    PYTHON_PID=$(pgrep -P "$WRAPPER_PID" | head -n1)
fi

# å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°±ç”¨ WRAPPER_PIDï¼ˆä¸å¤ªç†æƒ³ï¼Œä½†èƒ½ killï¼‰
if [ -z "$PYTHON_PID" ]; then
    PYTHON_PID="$WRAPPER_PID"
fi

# å†™å…¥ PID æ–‡ä»¶ï¼ˆè¿™æ˜¯ä½ åº”è¯¥ kill çš„ PIDï¼‰
echo "$PYTHON_PID" > "$PID_FILE"
echo "âœ… Recorded killable PID: $PYTHON_PID (saved in $PID_FILE)"

echo "ğŸ’¡ To stop training and free GPU memory, run:"
echo "      kill -9 \$(cat $PID_FILE)"
echo "   Or simply:"
echo "      kill -9 $PYTHON_PID"